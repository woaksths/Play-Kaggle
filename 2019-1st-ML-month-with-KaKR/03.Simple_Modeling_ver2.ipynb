{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./refine_data/train.csv')\n",
    "test = pd.read_csv('./refine_data/test.csv')\n",
    "\n",
    "label = train[\"Survived\"]\n",
    "features =[\"Sex\",\"Age_category\",\"Pclass\",\"Embarked_0\",\"Embarked_1\",\"Embarked_2\",\"family_cnt\",\"Age\"]\n",
    "train = train[features]\n",
    "test = test[features]\n",
    "\n",
    "\n",
    "# Todo\n",
    "# name의 성으로 연령대,성별 유추해보기\n",
    "# Age null - > mean 값으로 처리하기\n",
    "# fare attribute 추가해보기, null 데이터인지 그리고 normal 분포를 따르는지 체크. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Machine (Light gbm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(random_state=37,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y,test_y = train_test_split(train,label, test_size=0.3, random_state=37 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test_x = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_predict_test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission[\"Survived\"] = prediction_list\n",
    "submission.to_csv('./second_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coarse  Search  - 상위 5개의 score를 내는 하이퍼파라미터 구간들을 찾는다. Hold out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y,test_y = train_test_split(train,label, test_size=0.3, random_state=37 )\n",
    "\n",
    "n_estimators = 100\n",
    "num_loop =100\n",
    "early_stopping_rounds = 20\n",
    "coarse_hyperparameters_list = []\n",
    "\n",
    "for loop in range(num_loop):\n",
    "    num_leaves= np.random.randint(2,500)\n",
    "    max_bin = np.random.randint(2,500) \n",
    "    min_child_samples = np.random.randint(2, 500)\n",
    "    colsample_bytree =np.random.uniform(low= 0.1, high= 1.0)\n",
    "    learning_rate = 10** np.random.uniform(low = -10, high =1) \n",
    "    subsample = np.random.uniform(low= 0.1, high= 1.0)\n",
    "    model = LGBMClassifier(n_estimators = n_estimators,\n",
    "                           random_state=37,\n",
    "                           num_leaves=num_leaves,\n",
    "                           max_bin=max_bin,\n",
    "                           colsample_bytree=colsample_bytree,\n",
    "                           min_child_samples=min_child_samples,\n",
    "                           learning_rate=learning_rate,\n",
    "                           subsample=subsample,\n",
    "                           subsample_freq=1,\n",
    "                           class_type = 'balacned'\n",
    "                           )\n",
    "    model.fit(train_x,train_y,\n",
    "              eval_set = [(test_x,test_y)],\n",
    "              verbose = 0,\n",
    "              early_stopping_rounds = early_stopping_rounds\n",
    "             )\n",
    "    \n",
    "    y_predict_test_x = model.predict(test_x)\n",
    "    score = metrics.accuracy_score(y_predict_test_x, test_y)\n",
    "    coarse_hyperparameters_list.append({\n",
    "        'loop':loop,\n",
    "        'n_estimators':n_estimators,\n",
    "        'num_leaves':num_leaves,\n",
    "        'max_bin':max_bin,\n",
    "        'colsample_bytree':colsample_bytree,\n",
    "        'min_child_samples':min_child_samples,\n",
    "        'learning_rate':learning_rate,\n",
    "        'subsample':subsample,\n",
    "        'subsample_freq':1,\n",
    "        'class_type':'balanced',\n",
    "        'score': score\n",
    "    })\n",
    "coarse_hyperparameters_list = pd.DataFrame(coarse_hyperparameters_list)\n",
    "coarse_hyperparameters_list.sort_values(by='score', ascending =False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer Search - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y,test_y = train_test_split(train,label, test_size=0.3, random_state=37 )\n",
    "\n",
    "n_estimators = 100\n",
    "num_loop =100\n",
    "early_stopping_rounds = 20\n",
    "finer_hyperparameters_list = []\n",
    "\n",
    "for loop in range(num_loop):\n",
    "    num_leaves= np.random.randint(198,462)\n",
    "    max_bin = np.random.randint(70,290) \n",
    "    min_child_samples = np.random.randint(77, 146)\n",
    "    colsample_bytree =np.random.uniform(low= 0.25, high= 0.5)\n",
    "    learning_rate =  np.random.uniform(low = 0.01, high =1.32) \n",
    "    subsample = np.random.uniform(low= 0.39\t, high= 0.92)\n",
    "    \n",
    "    model = LGBMClassifier(n_estimators = n_estimators,\n",
    "                           random_state=37,\n",
    "                           num_leaves=num_leaves,\n",
    "                           max_bin=max_bin,\n",
    "                           colsample_bytree=colsample_bytree,\n",
    "                           min_child_samples=min_child_samples,\n",
    "                           learning_rate=learning_rate,\n",
    "                           subsample=subsample,\n",
    "                           subsample_freq=1,\n",
    "                           class_type = 'balacned'\n",
    "                           )\n",
    "    \n",
    "    model.fit(train_x,train_y,\n",
    "              eval_set = [(test_x,test_y)],\n",
    "              verbose = 0,\n",
    "              early_stopping_rounds = early_stopping_rounds\n",
    "             )\n",
    "    \n",
    "    y_predict_test_x = model.predict(test_x)\n",
    "    score = metrics.accuracy_score(y_predict_test_x, test_y)\n",
    "    finer_hyperparameters_list.append({\n",
    "        'loop':loop,\n",
    "        'n_estimators':n_estimators,\n",
    "        'num_leaves':num_leaves,\n",
    "        'max_bin':max_bin,\n",
    "        'colsample_bytree':colsample_bytree,\n",
    "        'min_child_samples':min_child_samples,\n",
    "        'learning_rate':learning_rate,\n",
    "        'subsample':subsample,\n",
    "        'subsample_freq':1,\n",
    "        'class_type':'balanced',\n",
    "        'score': score\n",
    "    })\n",
    "finer_hyperparameters_list = pd.DataFrame(finer_hyperparameters_list)\n",
    "finer_hyperparameters_list.sort_values(by='score', ascending =False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(n_estimators = 100,\n",
    "                       random_state=37,\n",
    "                       num_leaves=325,\n",
    "                       max_bin=211,\n",
    "                       colsample_bytree=0.416852,\n",
    "                       min_child_samples=84,\n",
    "                       learning_rate=1.022105,\n",
    "                       subsample=0.906650,\n",
    "                       subsample_freq=1,\n",
    "                       class_type = 'balacned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "%time model.fit(train_x,train_y)\n",
    "y_predict_test_x = model.predict(test_x)\n",
    "score = metrics.accuracy_score(y_predict_test_x, test_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission[\"Survived\"] = prediction_list\n",
    "submission.to_csv('./third_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
